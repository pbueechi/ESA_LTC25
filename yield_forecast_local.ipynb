{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881c94fe-8c41-4b42-8019-2e7ec9f35c01",
   "metadata": {},
   "source": [
    "# ESA LTC 2025 Crop Yield Forecasting\n",
    "\n",
    "Welcome to todays practical about crop yield forecasting üëã\n",
    "\n",
    "In this practical, we will develop a crop yield forecasting model based on Earth observation data and machine learning. By doing so, you will learn to:\n",
    "\n",
    "1. Analyze and clean crop yield data\n",
    "2. Extract time series from satellite data\n",
    "3. Prepare data for machine learning models\n",
    "4. Build simple predictive models\n",
    "5. Learn how to optimize models\n",
    "6. Understand the importance of the predictors\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e5688-f08f-4cd0-a817-acd37f09a188",
   "metadata": {},
   "source": [
    "The first step is to install the requried libraries and import them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af16b47-2b8c-4d0e-9d69-c0e1dbe8117d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2e3c3-742d-4065-bdbb-3e978afb2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import warnings\n",
    "import regionmask\n",
    "import netCDF4\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import xgboost as xgb\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, LeaveOneGroupOut, GridSearchCV\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, RFE, VarianceThreshold\n",
    "from scipy.stats import linregress\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "print(\"All libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754c82c-2238-4c4f-8ceb-86f8c5097e85",
   "metadata": {},
   "source": [
    "In this practical, we are using crop yield data provided by the Joint Research Centre. It can be found on https://agri4cast.jrc.ec.europa.eu/dataportal.\n",
    "It contains information about crop yields at a regional level for most countries of Europe. It is available for many crop types and years. In this practical, we are going to use the crop yield data of maize and spring barley only. For further crops go to their homepage and have a look yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61d30b-3f75-4810-b458-95abe4a5a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nüìä STEP 1: Loading and exploring crop yield data')\n",
    "\n",
    "# Load the crop yield CSV file\n",
    "# Expected columns: NUTS3_ID, Country, Year, Crop, Yield_tonnes_per_ha\n",
    "yield_data = pd.read_csv('data/yield_data_eurostat.csv', sep=';')\n",
    "\n",
    "# Show first few rows\n",
    "print(f'\\nüîç First 5 rows of the dataset:')\n",
    "print(yield_data.head())\n",
    "yield_data.loc[:, 'COUNTRY'] = [a[:2] for a in yield_data['IDREGION']]\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"\\nüìã Dataset Overview:\")\n",
    "print(f\"   ‚Ä¢ Time period: {yield_data['YEAR'].min()} - {yield_data['YEAR'].max()}\")\n",
    "print(f\"   ‚Ä¢ Countries: {yield_data['COUNTRY'].nunique()} ({', '.join(yield_data['COUNTRY'].unique())})\")\n",
    "print(f\"   ‚Ä¢ Crops: {yield_data['CROP_NAME'].nunique()} ({', '.join(yield_data['CROP_NAME'].unique())})\")\n",
    "print(f\"   ‚Ä¢ Number of NUTS3 regions: {yield_data['IDREGION'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d6f4a-b11d-4d85-9e3f-c5df6be0ec6c",
   "metadata": {},
   "source": [
    "This dataset has already been cleaned by JRC. Still, it makes sense to check for outliers and unusable values like 0, negative values, and nan. Hence, the next step is data cleaning. Finally, we are also aggregating the data to Nomenclature of Units for Territorial Statistics level 2 (NUTS2). These are larger areas than NUTS3, hence we loose some information about the spatial detail, however, the data will be less noisy too, since aggregating to larger areas reduces uncertainties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193c978-eb62-4dcb-9cdc-78d0d6204773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original data size\n",
    "original_size = len(yield_data)\n",
    "print(f'üìä Original dataset size: {original_size} rows')\n",
    "\n",
    "# Remove zero and negative values\n",
    "zero_mask = yield_data['VALUE'] <= 0\n",
    "zero_count = zero_mask.sum()\n",
    "yield_data_clean = yield_data[~zero_mask].copy()\n",
    "\n",
    "# Remove nan values\n",
    "with_nan_size = len(yield_data_clean)\n",
    "yield_data_clean = yield_data_clean.dropna(subset=['VALUE'])\n",
    "wo_nan_size = len(yield_data_clean)\n",
    "\n",
    "# Remove outliers using IQR method for each crop separately\n",
    "def remove_outliers_iqr(df, column, group_by=None):\n",
    "    \"\"\"Remove outliers using the Interquartile Range (IQR) method\"\"\"\n",
    "    if group_by:\n",
    "        outlier_mask = pd.Series(False, index=df.index)\n",
    "        for group in df[group_by].unique():\n",
    "            group_data = df[df[group_by] == group][column]\n",
    "            Q1 = group_data.quantile(0.25)\n",
    "            Q3 = group_data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 2 * IQR\n",
    "            upper_bound = Q3 + 2 * IQR\n",
    "            group_outliers = (group_data < lower_bound) | (group_data > upper_bound)\n",
    "            outlier_mask[group_data.index] = group_outliers\n",
    "        return ~outlier_mask\n",
    "    else:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 2 * IQR\n",
    "        upper_bound = Q3 + 2 * IQR\n",
    "        return (df[column] >= lower_bound) & (df[column] <= upper_bound)\n",
    "\n",
    "# Apply outlier removal for each crop\n",
    "outlier_mask = remove_outliers_iqr(yield_data_clean, 'VALUE', 'CROP_NAME')\n",
    "outlier_count = (~outlier_mask).sum()\n",
    "yield_data_clean = yield_data_clean[outlier_mask].copy()\n",
    "\n",
    "print(f'‚ùå Removed:\\n{zero_count} rows with zero and negative yield values\\n{with_nan_size-wo_nan_size} rows with NaN values\\n{outlier_count} outlier rows')\n",
    "print(f'‚úÖ Clean dataset size: {len(yield_data_clean)} rows')\n",
    "\n",
    "crops = yield_data['CROP_NAME'].unique()\n",
    "\n",
    "# Set up a 2x2 grid of subplots (2 crops x before/after)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "\n",
    "for i, crop in enumerate(crops):\n",
    "    # Filter by crop for both dataframes\n",
    "    yd_crop = yield_data[yield_data['CROP_NAME'] == crop]\n",
    "    ydc_crop = yield_data_clean[yield_data_clean['CROP_NAME'] == crop]\n",
    "\n",
    "    # Before cleaning\n",
    "    yd_crop['VALUE'].hist(bins=50, alpha=0.7, ax=axes[i, 0], color='red')\n",
    "    axes[i, 0].set_title(f'{crop} - Before Cleaning')\n",
    "    axes[i, 0].set_xlabel('Yield (t/ha)')\n",
    "    axes[i, 0].set_ylabel('Frequency')\n",
    "\n",
    "    # After cleaning\n",
    "    ydc_crop['VALUE'].hist(bins=50, alpha=0.7, ax=axes[i, 1], color='green')\n",
    "    axes[i, 1].set_title(f'{crop} - After Cleaning')\n",
    "    axes[i, 1].set_xlabel('Yield (t/ha)')\n",
    "    axes[i, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.suptitle('Effect of Data Cleaning on Yield Distribution by Crop')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# As a last step, lets reformat the yield data to NUTS2 regions to save computation power\n",
    "yield_data_clean['IDREGION'] = yield_data_clean['IDREGION'].str[:4]\n",
    "yield_data_clean = yield_data_clean.groupby(['IDREGION', 'CROP_NAME', 'VARIABLE', 'YEAR', 'COUNTRY'])['VALUE'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f8747-65d9-4844-affd-8f7c44bdf809",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned, we can have a look at the data in more detail. In the following part, we will compare the crop yields for the different countries and look at temporal trends. Have a look how the crop yields evolved over the last years in different countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4585b-d2e2-41fa-9642-843c314b6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by COUNTRY\n",
    "df_sorted = yield_data_clean.sort_values(by='COUNTRY')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_sorted, x='CROP_NAME', y='VALUE', hue='COUNTRY')\n",
    "\n",
    "# Get handles and labels for legend, sort them alphabetically\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "labels, handles = zip(*sorted(zip(labels, handles), key=lambda x: x[0]))\n",
    "\n",
    "plt.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.45), ncol=len(labels)/4)\n",
    "plt.title('Yield Distribution per Crop by Country')\n",
    "plt.xlabel('Crop Name')\n",
    "plt.ylabel('Yield (t/ha)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965963e9-4c13-4fa1-955f-21819caa1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'DE'  # Replace with your chosen country as above in the legend\n",
    "df_country = yield_data_clean[yield_data_clean['COUNTRY'] == country]\n",
    "crop_list = sorted(df_country['CROP_NAME'].unique())\n",
    "n_crops = len(crop_list)\n",
    "\n",
    "fig, axes = plt.subplots(1, n_crops, figsize=(6 * n_crops, 6), sharey=True)\n",
    "\n",
    "for idx, crop in enumerate(crop_list):\n",
    "    ax = axes[idx] if n_crops > 1 else axes\n",
    "\n",
    "    df_crop = df_country[df_country['CROP_NAME'] == crop]\n",
    "    sns.boxplot(data=df_crop, x='YEAR', y='VALUE', ax=ax)\n",
    "    ax.set_title(crop)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    if idx == 0:\n",
    "        ax.set_ylabel('Yield (t/ha)')\n",
    "    else:\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "    # Perform linear regression for trend line\n",
    "    # Convert YEAR to numeric (if not already)\n",
    "    x = df_crop['YEAR'].astype(int)\n",
    "    y = df_crop['VALUE']\n",
    "\n",
    "    # Set x-ticks to unique years, labels as year numbers (numeric)\n",
    "    years = sorted(df_crop['YEAR'].unique())\n",
    "    ax.set_xticks(range(len(years)))\n",
    "    ax.set_xticklabels(years, rotation=45)\n",
    "\n",
    "    # For linear regression x values, map years to positions 0,1,2...\n",
    "    x_positions = [years.index(year) for year in x]\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x_positions, y)\n",
    "    x_vals = np.arange(len(years))\n",
    "    y_vals = intercept + slope * x_vals\n",
    "\n",
    "    # Plot trend line\n",
    "    ax.plot(x_vals, y_vals, color='red', linestyle='--')\n",
    "\n",
    "    # Annotate slope and significance\n",
    "    annotation = f'Slope: {slope:.3f}\\nP-value: {p_value:.3e}'\n",
    "    ax.text(0.95, 0.05, annotation, transform=ax.transAxes,\n",
    "            verticalalignment='bottom', horizontalalignment='right',\n",
    "            fontsize=10, color='black', bbox=dict(boxstyle='round,pad=0.3', alpha=1.0))\n",
    "\n",
    "plt.suptitle(f'Yield per Year with Linear Trend for Country: {country}', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb2a71-29a9-48ef-a592-dafc5fa8bcba",
   "metadata": {},
   "source": [
    "Now that we got to know the crop yield data, we need some predictors to forecast crop yields. \n",
    "In this practical, we will use two key predictors: \n",
    "1) Soil moisture from ESA CCI\n",
    "2) Enhanced Vegetation Index from MODIS\n",
    "\n",
    "Soil moisture can be accurately derived from satellite data. ESA CCI soil moisture then merges the information from various satellites for having a long-term dataset. Here, we are using the ESA CCI Soil Moisture GAPFILLED dataset as produced and described by Preimesberger et al. (https://doi.org/10.5194/essd-17-4305-2025). The data is publicly available on https://researchdata.tuwien.ac.at/records/3fcxr-cde10. \n",
    "\n",
    "The Enhanced Vegetation Index (EVI) is provided by MODIS (https://modis.gsfc.nasa.gov/data/dataprod/mod13.php). This dataset is available at different spatial (from 250m to 0.05¬∞) and temporal resolutions (16d or monthly). To save calculation power, we use the one with the lowest spatial resolution of 0.05¬∞ and 16d.\n",
    "\n",
    "In addition to the predictor, we also need a shapefile which contains the regions that we want to model. This can be found on https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/territorial-units-statistics. With this file, we extract the predictors such that we have the mean of all pixel values laying within the individual areas.\n",
    "\n",
    "Before the extraction, let us have a look at the areas and the soil moisture data to get a feeling for the data. You can also have a look at different times in time by changing the index after first_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab82d5-45a6-40ad-ae43-bab8fd6d5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading NUTS areas and select NUTS2\n",
    "nuts_areas_gdf = gpd.read_file('data/NUTS_areas.shp')\n",
    "nuts_areas = nuts_areas_gdf[nuts_areas_gdf['LEVL_CODE'] == 2].copy()\n",
    "\n",
    "# Read soil moisture data\n",
    "soil_moisture_ds = xr.open_dataset('data/sm.nc')\n",
    "\n",
    "# Get the first time step from soil moisture data for visualization\n",
    "# You can also change the index to have a look at different timesteps.\n",
    "first_date = soil_moisture_ds.time.values[0]\n",
    "first_date_str = pd.Timestamp(first_date).strftime('%Y-%m-%d')\n",
    "\n",
    "# Extract soil moisture data for the first date\n",
    "sm_first_date = soil_moisture_ds.sel(time=first_date)['sm']\n",
    "\n",
    "# Create the spatial visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "\n",
    "# Plot soil moisture as background\n",
    "im = sm_first_date.plot(\n",
    "    ax=ax,\n",
    "    cmap='BrBG',\n",
    "    add_colorbar=False,  # We'll add a custom colorbar\n",
    "    alpha=1,\n",
    "    extend='both'\n",
    ")\n",
    "\n",
    "# Add colorbar for soil moisture\n",
    "cbar = plt.colorbar(im, ax=ax, orientation='horizontal',\n",
    "                   pad=0.05, shrink=0.8, aspect=30)\n",
    "cbar.set_label('Soil Moisture (m¬≥/m¬≥)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot NUTS3 boundaries on top\n",
    "nuts_areas.plot(\n",
    "    ax=ax,\n",
    "    facecolor='none',  # Transparent fill\n",
    "    edgecolor='black',   # Red boundaries\n",
    "    linewidth=0.8,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title(f'ESA CCI Soil Moisture with NUTS2 Boundaries\\n{first_date_str}',\n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Longitude (¬∞E)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Latitude (¬∞N)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Set appropriate extent (focus on Europe)\n",
    "if len(nuts_areas) > 0:\n",
    "    bounds = nuts_areas.total_bounds\n",
    "    lat_min, lat_max = soil_moisture_ds.lat.values.min(), soil_moisture_ds.lat.values.max()\n",
    "    lon_min, lon_max = soil_moisture_ds.lon.values.min(), soil_moisture_ds.lon.values.max()\n",
    "    ax.set_xlim(lon_min, lon_max)\n",
    "    ax.set_ylim(lat_min, lat_max)\n",
    "\n",
    "# Add grid for better orientation\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor='brown', alpha=0.8, label='Soil Moisture (background)'),\n",
    "    Patch(facecolor='none', edgecolor='black', linewidth=2, label='NUTS2 Area Boundaries')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right',\n",
    "          bbox_to_anchor=(0.98, 1.07), fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics about the spatial data\n",
    "print(f\"\\nüìä Spatial Analysis Results:\")\n",
    "print(f\"   ‚Ä¢ NUTS2 areas plotted: {len(nuts_areas)}\")\n",
    "print(f\"   ‚Ä¢ Soil moisture grid points: {sm_first_date.size:,}\")\n",
    "print(f\"   ‚Ä¢ Average soil moisture: {sm_first_date.mean().values:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435add9-3dda-415a-a2bb-88d86dce01ca",
   "metadata": {},
   "source": [
    "We can see that in the smaller regions there are not many observations but usually, we still have at least some pixels laying within the areas. The next step is to extract the predictors per area that we want to model. For this, we need to overlay the shapefile of the areas with the nc-files of the predictors.\n",
    "\n",
    "Note: in addition to simply extract all pixels per region, it is common practice to only consider pixels the are agricultural areas on land cover areas, or, even better, extract only data for fields on which the considered crop is cultivated per year. However, to decrease calculation time and since the data we are using has a coarse spatial resolution of 0.05 and 0.25¬∞, we neglect this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f4cfb-8aca-4d31-ac3a-623a99e5aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the shapefile, filter for LEVL_CODE == 2 -> NUTS2 areas\n",
    "gdf = gpd.read_file(\"data/NUTS_areas.shp\")\n",
    "regions_nuts2 = gdf[gdf[\"LEVL_CODE\"] == 2]\n",
    "names_dict = {a:b for a,b in zip(regions_nuts2.index.tolist(), regions_nuts2.NUTS_ID.tolist())}\n",
    "for dataset in [\"sm\", \"evi\"]:\n",
    "    print(f\"Starting extraction of {dataset} data\")\n",
    "    # 2. Read the NetCDF file\n",
    "    ds = xr.open_dataset(f\"data/{dataset}.nc\")\n",
    "    # 3. Create the regionmask\n",
    "    reg_mask = regionmask.Regions(name=\"regions\",\n",
    "                                  numbers=regions_nuts2.index.tolist(),\n",
    "                                  outlines=regions_nuts2.geometry.values,\n",
    "                                  names=regions_nuts2[\"NUTS_ID\"])\n",
    "    mask = reg_mask.mask(ds)\n",
    "    # 4. Calculate mean per region and time\n",
    "    means = ds[dataset].groupby(mask).mean()  # replace \"variable_name\" with the variable in nc\n",
    "    # 5. Convert to DataFrame and save as CSV\n",
    "    df = means.to_dataframe().unstack(level=0)\n",
    "    df.columns = df.columns.droplevel()\n",
    "    df.index = [names_dict[int(a)] for a in df.index]   # Renames the indices to NUTS_ID instead if region number\n",
    "    if dataset == \"evi\":\n",
    "        df = df/100000000   # This step is required as the MODIS data uses a scalefactor on their dataset.\n",
    "    df.to_csv(f\"data/{dataset}_reg.csv\")\n",
    "print(f\"‚úÖ All data extracted and saved as csv files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b0da5-ed59-4e8f-8bba-c9bc094856bf",
   "metadata": {},
   "source": [
    "Well done, that data has now been extracted. In the next step, we are plotting the timeseries to see how it looks like. Feel free to change the region_to_plot with any of the printed regions below and also the years under start_date and end_date -> have a look at a region you know and maybe experienced a drought over recent years. E.g. in 2018 there was a severe drought in most of central Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0dff7-8590-424c-b642-2f14f3e025e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "sm_df = pd.read_csv(\"data/sm_reg.csv\", index_col=0)\n",
    "evi_df = pd.read_csv(\"data/evi_reg.csv\", index_col=0)\n",
    "# Convert columns to datetime\n",
    "sm_df.columns = pd.to_datetime(sm_df.columns)\n",
    "evi_df.columns = pd.to_datetime(evi_df.columns)\n",
    "# List of available regions\n",
    "available_regions = sm_df.index.intersection(evi_df.index).tolist()\n",
    "print(\"Available regions:\", available_regions)\n",
    "# Specify the region and time range to plot\n",
    "region_to_plot = \"AT11\"\n",
    "start_date = \"2011-01-01\"\n",
    "end_date = \"2016-12-31\"\n",
    "# Select region and time window\n",
    "sm_series = sm_df.loc[region_to_plot]\n",
    "evi_series = evi_df.loc[region_to_plot]\n",
    "# Filter by date range\n",
    "sm_series = sm_series[(sm_series.index >= start_date) & (sm_series.index <= end_date)]\n",
    "evi_series = evi_series[(evi_series.index >= start_date) & (evi_series.index <= end_date)]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "color_sm = \"tab:blue\"\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(r\"Soil Moisture [m$^3$/m$^3$]\", color=color_sm)\n",
    "ax1.plot(sm_series.index, sm_series.values, color=color_sm, label=\"Soil Moisture\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color_sm)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color_evi = \"tab:green\"\n",
    "ax2.set_ylabel(\"EVI\", color=color_evi)\n",
    "ax2.plot(evi_series.index, evi_series.values, color=color_evi, label=\"EVI\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color_evi)\n",
    "\n",
    "# Set x-axis ticks to yearly intervals at start of each year\n",
    "years = mdates.YearLocator()\n",
    "year_fmt = mdates.DateFormatter(\"%Y\")\n",
    "ax1.xaxis.set_major_locator(years)\n",
    "ax1.xaxis.set_major_formatter(year_fmt)\n",
    "fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "plt.title(f\"Soil Moisture and EVI Time Series for {region_to_plot}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c7800-4a0f-490b-bfaf-4a27fb37ac5a",
   "metadata": {},
   "source": [
    "Can you see the impact of the drought on soil moisture or EVI values?\n",
    "\n",
    "We can see, that both datasets are already quite clean: no outliers nor gaps. In ML with EO data most time is usually spent to prepare the data, to smooth the timeseries, fill gaps etc. To not spend too much time on this during this practical, we focus on these two datasets.\n",
    "\n",
    "Now, we want to reformate this data such that it is usable for a machine learning model. We do this by aggregating the timeseries to monthly timesteps. This decreases the uncertainties in the data and leaves us with a lower amount of predictors.\n",
    "\n",
    "To do so, and to make all regions comparable, we select an approximate harvest date per country and start calculating back from this. I.e., maize harvesting season in Europe starts often beginning of September. Hence, the last month before harvest is August. The second to last month is July and so on. We call these months now lead time 0 and 1 (LT0 and LT1). We extract the datasets now such that we have several values over the growing period starting with LT6. This will result in 14 predictors in total (2 datasets: sm and evi and for each dataset 7 timesteps).\n",
    "\n",
    "Timeseries modelling: it is important to note here, that classical machine learning approaches cannot properly handle timeseries data. They take months as individual predictors but do not understand how they relate to each other. To make sense of the timeseries information deep learning models like Recurrent Neural Networks (e.g. Long Short-Term Memory) or Transformers are required. However, these require much more data for training than considered here and take longer for training. A common solution to tackle the issue of data scarcity is transfer learning. This is beyond the goal of this practical. If you are interested check: https://dx.doi.org/10.2139/ssrn.5108346\n",
    "\n",
    "For further good practices in machine learning check: https://doi.org/10.1021/acs.est.3c00026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706265c-d907-4a37-b136-fe8596a6dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take sm and evi data from above and aggregate to monthly means\n",
    "sm_df_monthly = sm_df.resample('M', axis=1).mean()\n",
    "evi_df_monthly = evi_df.resample('M', axis=1).mean()\n",
    "\n",
    "# Define start of the harvesting season, which is in Europe generally:\n",
    "# Spring Barley ~ July (7)\n",
    "# Maize ~ September (9)\n",
    "harvest_months = {\n",
    "    'spring barley': 7,\n",
    "    'maize': 9\n",
    "}\n",
    "\n",
    "# Map region prefix to continent or country grouping if needed (not specified, so use fixed harvest months)\n",
    "# Initialize containers for each crop type\n",
    "crop_types = yield_data_clean['CROP_NAME'].unique()\n",
    "\n",
    "# Process each crop type separately\n",
    "for crop in crop_types:\n",
    "    subset = yield_data_clean[yield_data_clean['CROP_NAME'] == crop].copy()\n",
    "\n",
    "    data_records = []\n",
    "\n",
    "    for idx, row in subset.iterrows():\n",
    "        region = row['IDREGION']\n",
    "        year = row['YEAR']\n",
    "        yield_val = row['VALUE']\n",
    "        crop_lower = crop.lower()\n",
    "\n",
    "        # Determine harvest month for this crop (could extend by country if info is available)\n",
    "        harvest_month = harvest_months.get(crop_lower, 7)\n",
    "        harvest_date = pd.Timestamp(year=year, month=harvest_month, day=1) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "        # Prepare dict for output row\n",
    "        output_row = {\n",
    "            'IDREGION': region,\n",
    "            'YEAR': year,\n",
    "            'CROP_NAME': crop,\n",
    "            'VALUE': yield_val\n",
    "        }\n",
    "\n",
    "        # For LT0 to LT6 lead times, get monthly aggregated predictor values\n",
    "        for lt in range(7):\n",
    "            # month for this lead time is harvest month minus LT months\n",
    "            predictor_month = harvest_date - pd.DateOffset(months=lt)\n",
    "\n",
    "            # Get month key matching the monthly aggregated predictor columns (end of month)\n",
    "            month_key = predictor_month\n",
    "\n",
    "            # For the given region, get the predictors for that month, fallback to NaN if missing\n",
    "            sm_val = np.nan\n",
    "            evi_val = np.nan\n",
    "            try:\n",
    "                sm_val = sm_df_monthly.at[region, month_key]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            try:\n",
    "                evi_val = evi_df_monthly.at[region, month_key]\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "            output_row[f'sm_LT{lt}'] = sm_val\n",
    "            output_row[f'evi_LT{lt}'] = evi_val\n",
    "\n",
    "        data_records.append(output_row)\n",
    "\n",
    "    # Create DataFrame for this crop type\n",
    "    crop_out_df = pd.DataFrame.from_records(data_records)\n",
    "\n",
    "    # Save to CSV\n",
    "    output_filename = f'data/yield_predictors_{crop.lower().replace(\" \", \"_\")}.csv'\n",
    "    crop_out_df = crop_out_df.dropna(axis=0, how='any')\n",
    "    crop_out_df.to_csv(output_filename, index=False)\n",
    "\n",
    "    print(f'Saved {output_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63e3c2-f21e-46c5-a0f6-f2f8c07ec439",
   "metadata": {},
   "source": [
    "Now that the predictor files are ready, we can start with the modelling... For the start we will just use an Extreme Gradient Boosting approach, which is one of the most commonly used approaches for crop yield modelling using EO data. In a later step, we will use some more models. \n",
    "\n",
    "Choose your own model setup! Which crop should be forecasted? And how many months before harvest do you want to do so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f2cea-535a-4101-b126-abfc0c82dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the crop you want to model, the lead times and the validation metric\n",
    "crop = \"spring_barley\"  # Choose from grain_maize and spring_barley\n",
    "lead_times = [0, 2, 4]  # Months before harvest season, choose from 0 to 6\n",
    "metric = \"r2\"           # Choose from explained_variance, r2, neg_mean_absolute_percentage_error\n",
    "\n",
    "path = f'data/yield_predictors_{crop}.csv'\n",
    "file = pd.read_csv(path)\n",
    "\n",
    "# Dictionary to store results for each lead time\n",
    "results_dict = {}\n",
    "scores_list = []\n",
    "lead_time_labels = []\n",
    "\n",
    "# Loop through each lead time\n",
    "for lead_time in lead_times:\n",
    "    print(f\"Processing lead time: {lead_time}\")\n",
    "\n",
    "    # Get predictors for current lead time\n",
    "    predictors = [col for col in file.columns if col[-3:-1]==\"LT\"]\n",
    "    used_predictors = [a for a in predictors if int(a[-1]) >= lead_time]\n",
    "\n",
    "    # Prepare data\n",
    "    X = file.loc[:, used_predictors]\n",
    "    years = file.loc[:, 'YEAR']\n",
    "    regs = file.loc[:, 'IDREGION']\n",
    "\n",
    "    X.index = pd.to_datetime(years.values, format=\"%Y\")\n",
    "    y = file.loc[:, 'VALUE']\n",
    "\n",
    "    # Define model and pipeline\n",
    "    estimator = xgb.XGBRegressor(\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        random_state=42  # Added for reproducibility\n",
    "    )\n",
    "    pipe_xgb = Pipeline([('scalar', StandardScaler()), ('clf', estimator)])\n",
    "\n",
    "    # Cross-validation\n",
    "    groups = years\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    scores = cross_validate(pipe_xgb, X, y, cv=logo, groups=groups, scoring=metric,\n",
    "                           n_jobs=30, return_train_score=False)['test_score']\n",
    "\n",
    "    # Store results\n",
    "    results_dict[f'Lead Time {lead_time}'] = scores\n",
    "\n",
    "    # Prepare data for boxplot\n",
    "    scores_list.extend(scores)\n",
    "    lead_time_labels.extend([f'LT {lead_time}'] * len(scores))\n",
    "\n",
    "    print(f\"Lead time {lead_time}: Mean score = {scores.mean():.4f}, Std = {scores.std():.4f}\")\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "plot_data = pd.DataFrame({\n",
    "    'Lead Time': lead_time_labels,\n",
    "    'Explained Variance': scores_list\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4c1e9-ae1c-4f3b-b243-8b747ee160bf",
   "metadata": {},
   "source": [
    "For better analysis lets make a plot of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ffcb0-410b-4854-bc69-c3587d698871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.boxplot(data=plot_data, x='Lead Time', y='Explained Variance')\n",
    "plt.title(f'Model Performance by Lead Time of {crop}', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Lead Time')\n",
    "plt.ylabel('Explained Variance Score')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Since there are some outliers, lets zoom in to R¬≤ range from -1 to 1 by uncommenting the following function:\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a9b476-a044-45fd-a64f-327a3cacaace",
   "metadata": {},
   "source": [
    "Well done! You just did your (first?) crop yield forecast for most of Europe! Lets have a look at the forecasts and how they differ from observed yields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4114d33-39e3-4cbb-80e4-c20848fb3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time = 0          # For the visualisation, we focus on the last lead time. But you can also adjust this with a value from 0-6\n",
    "\n",
    "# Get predictors for current lead time\n",
    "predictors = [col for col in file.columns if col[-3:-1]==\"LT\"]\n",
    "used_predictors = [a for a in predictors if int(a[-1]) >= lead_time]\n",
    "\n",
    "# Lets make a forecast for the latest year in the dataset 2022\n",
    "# Thus, we split the data into training (years before 2022) and testing (year 2022)\n",
    "test_ind = np.where(file.loc[:, 'YEAR']==2022)[0]\n",
    "train_ind = np.where(file.loc[:, 'YEAR']!=2022)[0]\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test = file.loc[train_ind, used_predictors], file.loc[test_ind, used_predictors]\n",
    "y_train, y_test = file.loc[train_ind, 'VALUE'], file.loc[test_ind, 'VALUE']\n",
    "regs = file.loc[test_ind, 'IDREGION']\n",
    "\n",
    "# Define model and pipeline\n",
    "estimator = xgb.XGBRegressor(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42  # Added for reproducibility\n",
    ")\n",
    "pipe_xgb = Pipeline([('scalar', StandardScaler()), ('clf', estimator)])\n",
    "pipe_xgb.fit(X_train, y_train)\n",
    "y_pred = pipe_xgb.predict(X_test)\n",
    "\n",
    "data_df = pd.DataFrame({\n",
    "    'region_name': regs,\n",
    "    'y_test': y_test,\n",
    "    'y_pred': y_pred\n",
    "})\n",
    "\n",
    "# Merge the shapefile with your data\n",
    "# Replace 'REGION_NAME_COLUMN' with the actual column name in your shapefile that contains region names\n",
    "gdf_merged = nuts_areas.merge(data_df, left_on='NUTS_ID', right_on='region_name', how='left')\n",
    "\n",
    "# Calculate shared colorbar range\n",
    "vmin = min(min(y_test), min(y_pred))\n",
    "vmax = max(max(y_test), max(y_pred))\n",
    "norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Create the three plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: Spatial plot colored by y_test\n",
    "gdf_merged.plot(column='y_test',\n",
    "                ax=axes[0],\n",
    "                cmap='viridis',\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                edgecolor='black',\n",
    "                linewidth=0.5)\n",
    "axes[0].set_title('Actual Values (y_test)', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Plot 2: Spatial plot colored by y_pred\n",
    "gdf_merged.plot(column='y_pred',\n",
    "                ax=axes[1],\n",
    "                cmap='viridis',\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                edgecolor='black',\n",
    "                linewidth=0.5)\n",
    "axes[1].set_title('Predicted Values (y_pred)', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Add colorbar between first two plots\n",
    "sm = cm.ScalarMappable(norm=norm, cmap='viridis')\n",
    "sm.set_array([])\n",
    "# Position the colorbar between axes[0] and axes[1]\n",
    "cbar_ax = fig.add_axes([0.31, 0.15, 0.01, 0.7])  # [left, bottom, width, height]\n",
    "cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "cbar.set_label('Yield [t/ha]', fontsize=14)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "# Plot 3: Scatterplot with x=y line\n",
    "axes[2].scatter(y_test, y_pred, alpha=0.7)\n",
    "axes[2].set_xlabel('y_test (Actual)', fontsize=14)\n",
    "axes[2].set_ylabel('y_pred (Predicted)', fontsize=14)\n",
    "axes[2].set_title('Predicted vs Actual', fontsize=16)\n",
    "axes[2].tick_params(labelsize=12)\n",
    "\n",
    "# Add x=y line\n",
    "min_val = min(min(y_test), min(y_pred))\n",
    "max_val = max(max(y_test), max(y_pred))\n",
    "initial_perf = np.round(r2_score(y_test, y_pred),2)\n",
    "axes[2].plot([min_val, max_val], [min_val, max_val], 'r--', label=f'x=y\\n R¬≤={initial_perf}')\n",
    "axes[2].set_xlim(min_val, max_val)\n",
    "axes[2].set_ylim(min_val, max_val)\n",
    "axes[2].legend(fontsize=12)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9ffba-7085-4752-878f-a6ab6b409bf0",
   "metadata": {},
   "source": [
    "Nice, the model ran smoothly, but we can see that the model is not really optimal yet. Usually the model can be further improved by different means:\n",
    " * Model selection\n",
    " * Hyperparameter-tuning\n",
    " * Feature selection\n",
    " * Data cleaning/preparation (anomaly calculation, adjust outlier removal, detrending)\n",
    " * Add more information as predictors, like year, country, latitude...\n",
    " * Remove data from training (regions with high uncertainties, split area into areas that are more \"alike\")\n",
    " * ...\n",
    "\n",
    "For the sake of time, we are going to focus on the first three points only. Lets start with model selection. In this example we are using three classical ML approaches. Feel free to check out other models from sklearn and simply replace the models that are used now in the following code.\n",
    "\n",
    "The three models that are used in this example are Extreme Gradient Boosting (XGBoost - a tree based algorithm), Support Vector Regression (SVR - uses hyperplane), and Multi-layer Perceptron (MLP - type of Artificial Neural Networks). These are some common approaches for ML modelling. However, if you want to use different approaches go to https://scikit-learn.org/stable/supervised_learning.html and select any approach you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407c537-212f-4e7d-aa1b-3e35092c9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before validating different models, we need to make another subsplit of the data. So far we have just used train and test data, but now, we also need a validation split. For this we retain the last 20% of the years for testing only. This step is done in the following function.\n",
    "# Define models to compare\n",
    "lead_times = [0, 1]  # For now, we focus on the latest two lead-times to save computing power.\n",
    "\n",
    "models = {\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'SVM': SVR(\n",
    "        kernel='rbf',\n",
    "        C=1.0,\n",
    "        gamma='scale'\n",
    "    ),\n",
    "    # 'Ridge': Ridge(),\n",
    "    'MLP': MLPRegressor(\n",
    "        hidden_layer_sizes=(100,),\n",
    "        activation='relu',\n",
    "        learning_rate='constant',\n",
    "    )\n",
    "}\n",
    "\n",
    "def train_test_split(file, lead_time, print_shape=False):\n",
    "    # Get predictors for current lead time\n",
    "    predictors = [col for col in file.columns if col[-3:-1]==\"LT\"]\n",
    "    used_predictors = [a for a in predictors if int(a[-1]) >= lead_time]\n",
    "\n",
    "    # Prepare data\n",
    "    X = file.loc[:, used_predictors]\n",
    "    years = file.loc[:, 'YEAR']\n",
    "\n",
    "    X.index = pd.to_datetime(years.values, format=\"%Y\")\n",
    "    y = file.loc[:, 'VALUE']\n",
    "\n",
    "    # Remove test years from validation:\n",
    "    # Split data into training (first 80%) and testing (last 20%) based on years\n",
    "    unique_years = sorted(years.unique())\n",
    "    train_cutoff = int(len(unique_years) * 0.8)\n",
    "    train_years = unique_years[:train_cutoff]\n",
    "    test_years = unique_years[train_cutoff:]\n",
    "\n",
    "    # Create train/test splits\n",
    "    train_mask = years.isin(train_years)\n",
    "    train_mask = np.where(train_mask==True)[0]\n",
    "    test_mask = years.isin(test_years)\n",
    "    test_mask = np.where(test_mask==True)[0]\n",
    "\n",
    "    X_train = X.iloc[train_mask, :]\n",
    "    y_train = y.iloc[train_mask]\n",
    "    years_train = years[train_mask]\n",
    "\n",
    "    X_test = X.iloc[test_mask, :]\n",
    "    y_test = y.iloc[test_mask]\n",
    "    years_test = years[test_mask]\n",
    "    if print_shape:\n",
    "        print(f\"Training years: {min(train_years)} - {max(train_years)} ({len(train_years)} years)\")\n",
    "        print(f\"Testing years: {min(test_years)} - {max(test_years)} ({len(test_years)} years)\")\n",
    "        print(f\"Training samples: {X_train.shape[0]}\")\n",
    "        print(f\"Testing samples: {X_test.shape[0]}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, years_train, years_test\n",
    "\n",
    "# Lists to store results for plotting\n",
    "scores_list = []\n",
    "lead_time_labels = []\n",
    "model_labels = []\n",
    "\n",
    "# Dictionary to store detailed results\n",
    "results_dict = {}\n",
    "\n",
    "# Loop through each model and lead time\n",
    "for model_name, estimator in models.items():\n",
    "    print(f\"\\n{'='*20} {model_name} {'='*20}\")\n",
    "\n",
    "    for lead_time in lead_times:\n",
    "        print(f\"Processing {model_name} with lead time: {lead_time}\")\n",
    "\n",
    "        X_train, X_test, y_train, y_test, years_train, years_test = train_test_split(file, lead_time, print_shape=True)\n",
    "\n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([('scalar', StandardScaler()), ('clf', estimator)])\n",
    "\n",
    "        # Cross-validation\n",
    "        groups = years_train\n",
    "        logo = LeaveOneGroupOut()\n",
    "        metric = \"r2\"\n",
    "\n",
    "        scores = cross_validate(pipeline, X_train, y_train, cv=logo, groups=groups, scoring=metric,\n",
    "                               return_train_score=False)['test_score']\n",
    "\n",
    "        # Store results for plotting\n",
    "        scores_list.extend(scores)\n",
    "        lead_time_labels.extend([f'LT {lead_time}'] * len(scores))\n",
    "        model_labels.extend([model_name] * len(scores))\n",
    "\n",
    "        # Store detailed results\n",
    "        key = f'{model_name}_LT_{lead_time}'\n",
    "        results_dict[key] = scores\n",
    "\n",
    "        print(f\"  Mean score = {scores.mean():.4f}, Std = {scores.std():.4f}\")\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "plot_data = pd.DataFrame({\n",
    "    'Lead Time': lead_time_labels,\n",
    "    'Model': model_labels,\n",
    "    'Explained Variance': scores_list\n",
    "})\n",
    "\n",
    "# Create the comparison plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Boxplot comparing models across lead times\n",
    "sns.boxplot(data=plot_data, x='Lead Time', y='Explained Variance', hue='Model', ax=ax1)\n",
    "ax1.set_title('Model Performance Comparison by Lead Time', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Lead Time')\n",
    "ax1.set_ylabel('Explained Variance Score')\n",
    "ax1.legend(title='', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Boxplot comparing lead times across models\n",
    "sns.boxplot(data=plot_data, x='Model', y='Explained Variance', hue='Lead Time', ax=ax2)\n",
    "ax2.set_title('Lead Time Comparison by Model', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Model')\n",
    "ax2.set_ylabel('Explained Variance Score')\n",
    "ax2.legend(title='', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6452a469-1916-476e-af96-c6181a9ea2b8",
   "metadata": {},
   "source": [
    "As a next step, we will do feature selection, which can further improve the performance and decrease the computing time. There are many different ways to define the best predictors. Here we will focus on 3 ways to do so:\n",
    "\n",
    "1) Variance Threshold - This method removes features that have low variance across samples. Features with very low variance are likely to be constant or quasi-constant, meaning they provide little information for distinguishing between different outcomes. If a feature has the same or nearly the same value for most samples, it won't be useful for prediction. The method calculates the variance of each feature and removes those below a threshold.\n",
    "2) Mutual Information Selection - Mutual Information measures the amount of information that knowing the value of one variable gives about another variable. Unlike correlation, it can capture non-linear relationships between features and the target. MI calculates how much uncertainty in the target variable is reduced by knowing a feature's value. Higher MI scores indicate that the feature provides more information about the target, making it more valuable for prediction.\n",
    "3) Recursive Feature Elimination - RFE is a wrapper method that works by recursively training a model and eliminating the least important features. It starts with all features, trains an XGBoost model, ranks features by importance, removes the least important feature(s), and repeats until the desired number of features remains. This process ensures that feature interactions are considered, as the model evaluates features in combination rather than individually. XGBoost is particularly good at capturing complex patterns and feature interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c53b125-6372-4b29-9798-1aa7691a0a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE SELECTION AND ELIMINATION\n",
    "# ============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test, years_train, years_test = train_test_split(file, lead_time=0)\n",
    "\n",
    "print(f\"\\nüîç Feature Selection and Elimination\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(f\"üîÑ Starting with {X_train.shape[1]} features...\")\n",
    "original_features = X_train.columns.tolist()\n",
    "\n",
    "# ============================================================================\n",
    "# METHOD 1: VARIANCE THRESHOLD\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüìà Method 1: Variance Threshold\")\n",
    "print(\"Removes features with low variance (constant/quasi-constant values)\")\n",
    "variance_threshold = 0.0005\n",
    "var_selector = VarianceThreshold(threshold=variance_threshold)\n",
    "X_train_var = var_selector.fit_transform(X_train)\n",
    "X_test_var = var_selector.transform(X_test)\n",
    "\n",
    "selected_var_features = X_train.columns[var_selector.get_support()].tolist()\n",
    "print(f\"‚úÖ Kept: {len(selected_var_features)} features\")\n",
    "\n",
    "# ============================================================================\n",
    "# METHOD 2: MUTUAL INFORMATION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüîó Method 2: Mutual Information\")\n",
    "print(\"Captures non-linear relationships between features and target\")\n",
    "\n",
    "k_best = min(10, X_train_var.shape[1])\n",
    "mi_selector = SelectKBest(score_func=mutual_info_regression, k=k_best)\n",
    "X_train_mi = mi_selector.fit_transform(X_train_var, y_train)\n",
    "X_test_mi = mi_selector.transform(X_test_var)\n",
    "\n",
    "mi_scores = mi_selector.scores_\n",
    "selected_mi_indices = mi_selector.get_support(indices=True)\n",
    "selected_mi_features = [selected_var_features[i] for i in selected_mi_indices]\n",
    "\n",
    "print(f\"‚úÖ Selected: {len(selected_mi_features)} features\")\n",
    "\n",
    "# Display top features\n",
    "mi_scores_df = pd.DataFrame({\n",
    "    'feature': selected_var_features,\n",
    "    'mi_score': mi_scores\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "print(f\"üìä Top 5 features by MI-score:\")\n",
    "print(mi_scores_df.head(5)[['feature', 'mi_score']].to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# METHOD 3: RECURSIVE FEATURE ELIMINATION WITH XGBoost\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüîÑ Method 3: RFE with XGBoost\")\n",
    "print(\"Iterative selection considering feature interactions using XGBoost\")\n",
    "\n",
    "rfe_estimator = xgb.XGBRegressor(\n",
    "    n_estimators=50,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "n_features_rfe = min(8, X_train_var.shape[1])\n",
    "\n",
    "rfe_selector = RFE(estimator=rfe_estimator, n_features_to_select=n_features_rfe, step=1)\n",
    "X_train_rfe = rfe_selector.fit_transform(X_train_var, y_train)\n",
    "X_test_rfe = rfe_selector.transform(X_test_var)\n",
    "\n",
    "selected_rfe_indices = rfe_selector.get_support(indices=True)\n",
    "selected_rfe_features = [selected_var_features[i] for i in selected_rfe_indices]\n",
    "\n",
    "print(f\"‚úÖ Selected: {len(selected_rfe_features)} features\")\n",
    "print(f\"üìä RFE selected features: {selected_rfe_features}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONSENSUS FEATURE SELECTION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nü§ù Consensus Feature Selection\")\n",
    "\n",
    "# Find features selected by multiple methods\n",
    "all_methods_features = {\n",
    "    'Variance Threshold': set(selected_var_features),\n",
    "    'Mutual Info': set(selected_mi_features),\n",
    "    'RFE': set(selected_rfe_features)\n",
    "}\n",
    "\n",
    "feature_counts = {}\n",
    "for method_features in all_methods_features.values():\n",
    "    for feature in method_features:\n",
    "        feature_counts[feature] = feature_counts.get(feature, 0) + 1\n",
    "\n",
    "# Find consensus features (selected by ‚â•2 methods)\n",
    "consensus_threshold = 2\n",
    "consensus_features = [feature for feature, count in feature_counts.items()\n",
    "                     if count >= consensus_threshold]\n",
    "\n",
    "if consensus_features:\n",
    "    final_selected_features = consensus_features\n",
    "    consensus_indices = [original_features.index(f) for f in consensus_features]\n",
    "    X_train_selected = X_train.iloc[:, consensus_indices]\n",
    "    X_test_selected = X_test.iloc[:, consensus_indices]\n",
    "    print(f\"üìä Consensus features: {len(consensus_features)}\")\n",
    "    print(f\"‚úÖ Features: {consensus_features}\")\n",
    "else:\n",
    "    # Fallback to RFE selection\n",
    "    final_selected_features = selected_rfe_features\n",
    "    X_train_selected = pd.DataFrame(X_train_rfe, columns=selected_rfe_features, index=X_train.index)\n",
    "    X_test_selected = pd.DataFrame(X_test_rfe, columns=selected_rfe_features, index=X_test.index)\n",
    "    print(f\"üìä No consensus found, using RFE selection\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüìà Creating visualization...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. Method comparison\n",
    "methods = ['Variance\\nThreshold', 'Mutual\\nInfo', 'RFE']\n",
    "n_selected = [len(selected_var_features), len(selected_mi_features), len(selected_rfe_features)]\n",
    "\n",
    "bars = axes[0].bar(methods, n_selected, color=['lightblue', 'lightgreen', 'lightcoral'])\n",
    "axes[0].set_title('Features Selected by Method')\n",
    "axes[0].set_ylabel('Number of Features')\n",
    "\n",
    "for i, count in enumerate(n_selected):\n",
    "    axes[0].text(i, count + 0.5, f'{count}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Top MI scores\n",
    "top_mi = mi_scores_df.head(8)\n",
    "axes[1].barh(range(len(top_mi)), top_mi['mi_score'])\n",
    "axes[1].set_yticks(range(len(top_mi)))\n",
    "axes[1].set_yticklabels([f[:15] + '...' if len(f) > 15 else f for f in top_mi['feature']])\n",
    "axes[1].set_title('Top Mutual Information Scores')\n",
    "axes[1].set_xlabel('MI Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüéØ FINAL FEATURE SELECTION RESULTS:\")\n",
    "print(f\"   ‚Ä¢ Original features: {len(original_features)}\")\n",
    "print(f\"   ‚Ä¢ Selected features: {len(final_selected_features)}\")\n",
    "print(f\"   ‚Ä¢ Reduction: {(1-len(final_selected_features)/len(original_features))*100:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Method used: {'Consensus' if consensus_features else 'RFE'}\")\n",
    "print(f\"   ‚Ä¢ Final features: {final_selected_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62ae1a-ecec-4649-8c15-e39eead56330",
   "metadata": {},
   "source": [
    "Having a model with less predictors helps to decrease computational time. However, did it also help to improve the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70417b-4601-4e78-bfe2-a126177a9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your model: \"XGBoost\", \"SVM\", \"MLP\"\n",
    "MODEL = \"SVM\"\n",
    "estimator = models[MODEL]\n",
    "\n",
    "main_columns = ['IDREGION', 'YEAR', 'CROP_NAME', 'VALUE']\n",
    "all_columns = file.columns.tolist()\n",
    "feature_columns = [col for col in all_columns if col not in main_columns]\n",
    "\n",
    "#Or you can also do your own selection of predictors just select some of the predictors from the following list:\n",
    "# final_selected_features = ['sm_LT0', 'evi_LT0', 'sm_LT1', 'evi_LT1', 'sm_LT2', 'evi_LT2', 'sm_LT3', 'evi_LT3', 'sm_LT4', 'evi_LT4', 'sm_LT5', 'evi_LT5', 'sm_LT6', 'evi_LT6']\n",
    "\n",
    "columns_to_keep = main_columns + final_selected_features\n",
    "\n",
    "# Filter dataframe\n",
    "file_filtered = file[columns_to_keep].copy()\n",
    "\n",
    "# Prepare data\n",
    "X_train_fe, X_test_fe, y_train_fe, y_test_fe, years_train_fe, years_test_fe = train_test_split(file_filtered, lead_time)\n",
    "X_train, X_test, y_train, y_test, years_train, years_test = train_test_split(file, lead_time)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([('scalar', StandardScaler()), ('clf', estimator)])\n",
    "\n",
    "# Cross-validation\n",
    "groups = years_train\n",
    "logo = LeaveOneGroupOut()\n",
    "metric = \"r2\"\n",
    "\n",
    "scores_fe = cross_validate(pipeline, X_train_fe, y_train_fe, cv=logo, groups=groups, scoring=metric, return_train_score=False)['test_score']\n",
    "scores = cross_validate(pipeline, X_train, y_train, cv=logo, groups=groups, scoring=metric, return_train_score=False)['test_score']\n",
    "\n",
    "print(f'R¬≤ of the original features: {np.mean(scores).round(2)} and after feature elimination: {np.mean(scores_fe).round(2)}\\n change in performance before and after feature elimination: {np.round(np.mean(scores_fe)-np.mean(scores),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc8ecbc-e9d7-4d03-af74-9b154bac5c59",
   "metadata": {},
   "source": [
    "Perfect, so now we will focus on the best model and try to further optimize it using hyperparameter tuning. The hyperparameters of a model define the structure of the model. For example the tree based algorithms XGB and random forest, there are hyperparameters like n_estimators which are the numer of decision trees that are used (often is somewhere between from 50 to 500) and max_depth which describes the maximum depth per decision trees (i.e. how many levels of decisions are done. This often ranges form 5 to 50). For each model there are dozens of hyperparameters. However, here, we just focus on the 2-3 most important ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86e713-4bfb-4044-b69b-b46205dae82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your lead time\n",
    "lead_time = 0\n",
    "\n",
    "feature_elimination = True  # Should we use the feature elimination or should we do the hp tuning on all features?\n",
    "\n",
    "# =============================================================================\n",
    "# HYPERPARAMETER TUNING ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"HYPERPARAMETER TUNING: {MODEL.upper()} - Lead Time {lead_time}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prepare data\n",
    "if feature_elimination:\n",
    "    used_file = file_filtered\n",
    "else:\n",
    "    used_file = file\n",
    "\n",
    "X_train, X_test, y_train, y_test, years_train, years_test = train_test_split(used_file, lead_time)\n",
    "\n",
    "# Set up cross-validation for training set only\n",
    "groups_train = years_train\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: BASELINE MODEL PERFORMANCE\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"STEP 1: BASELINE MODEL PERFORMANCE\")\n",
    "print(f\"{'-'*50}\")\n",
    "\n",
    "# Create baseline pipeline\n",
    "baseline_pipeline = Pipeline([('scalar', StandardScaler()), ('clf', estimator)])\n",
    "\n",
    "print(\"Running baseline model on training set...\")\n",
    "baseline_scores = cross_validate(\n",
    "    baseline_pipeline, X_train, y_train,\n",
    "    cv=logo,\n",
    "    groups=groups_train,\n",
    "    scoring='explained_variance',\n",
    ")['test_score']\n",
    "\n",
    "baseline_mean_cv = baseline_scores.mean()\n",
    "baseline_std_cv = baseline_scores.std()\n",
    "\n",
    "print(f\"Baseline Performance (Cross-Validation on Training Set):\")\n",
    "print(f\"  Mean CV Score: {baseline_mean_cv:.4f}\")\n",
    "print(f\"  Std Dev:       {baseline_std_cv:.4f}\")\n",
    "print(f\"  Min Score:     {baseline_scores.min():.4f}\")\n",
    "print(f\"  Max Score:     {baseline_scores.max():.4f}\")\n",
    "\n",
    "# Also fit baseline model on full training set for later testing\n",
    "print(\"Fitting baseline model on full training set...\")\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: HYPERPARAMETER TUNING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"STEP 2: HYPERPARAMETER TUNING\")\n",
    "print(f\"{'-'*50}\")\n",
    "\n",
    "# Define parameter grids\n",
    "if MODEL == \"MLP\":\n",
    "    param_grid = {\n",
    "        'clf__hidden_layer_sizes': [(100,), (50,), (50, 50,)],\n",
    "        'clf__activation': ['relu', 'logistic'],\n",
    "        'clf__learning_rate': ['constant', 'adaptive']\n",
    "    }\n",
    "    tuning_model = MLPRegressor()\n",
    "\n",
    "elif MODEL == \"XGBoost\":\n",
    "    param_grid = {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__max_depth': [3, 5, 7],\n",
    "        'clf__learning_rate': [0.01, 0.1, 0.2]\n",
    "    }\n",
    "    tuning_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "elif MODEL == \"SVM\":\n",
    "    param_grid = {\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__gamma': ['auto', 0.001, 0.01],\n",
    "        'clf__epsilon': [0.01, 0.1, 0.2]\n",
    "    }\n",
    "    tuning_model = SVR(kernel='rbf')\n",
    "\n",
    "# Calculate total combinations\n",
    "total_combinations = 1\n",
    "for param, values in param_grid.items():\n",
    "    total_combinations *= len(values)\n",
    "\n",
    "print(f\"Parameter grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param.replace('clf__', '')}: {values}\")\n",
    "print(f\"Total combinations to test: {total_combinations}\")\n",
    "print(f\"Cross-validation folds: {len(years_train)} (one for each training year)\")\n",
    "\n",
    "print(\"\\nRunning hyperparameter tuning on training set...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Create tuning pipeline\n",
    "tuning_pipeline = Pipeline([('scalar', StandardScaler()), ('clf', tuning_model)])\n",
    "\n",
    "# Run GridSearchCV on training set only\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tuning_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=logo,\n",
    "    scoring='explained_variance',\n",
    "    n_jobs=30,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: TEST SET EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Evaluate baseline model on test set\n",
    "baseline_pred = baseline_pipeline.predict(X_test)\n",
    "\n",
    "baseline_test_score = explained_variance_score(y_test, baseline_pred)\n",
    "baseline_mse = mean_squared_error(y_test, baseline_pred)\n",
    "baseline_r2 = r2_score(y_test, baseline_pred)\n",
    "\n",
    "# Evaluate tuned model on test set\n",
    "tuned_pred = grid_search.best_estimator_.predict(X_test)\n",
    "tuned_test_score = explained_variance_score(y_test, tuned_pred)\n",
    "tuned_mse = mean_squared_error(y_test, tuned_pred)\n",
    "tuned_r2 = r2_score(y_test, tuned_pred)\n",
    "\n",
    "# Calculate improvements\n",
    "improvement = tuned_test_score - baseline_test_score\n",
    "improvement_pct = (improvement / baseline_test_score) * 100 if baseline_test_score != 0 else 0\n",
    "mse_improvement = ((baseline_mse - tuned_mse) / baseline_mse) * 100 if baseline_mse != 0 else 0\n",
    "\n",
    "print(f\"\\nüìä FINAL MODEL COMPARISON (Test Set Performance):\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"                     Baseline    Tuned      Improvement\")\n",
    "print(f\"                     --------    -----      -----------\")\n",
    "print(f\"R¬≤ Score:            {baseline_r2:.4f}     {tuned_r2:.4f}     {tuned_r2-baseline_r2:+.4f}\")\n",
    "print(f\"MSE:                 {baseline_mse:.4f}     {tuned_mse:.4f}     {mse_improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d267660-9e0d-43bf-abcc-de847cfe6303",
   "metadata": {},
   "source": [
    "Here, we only used very few hyperparameter settings for computational reasons. Hence, maybe this was not enough to improve the performance. You can always adjust the used hyperparameters and try to get a better performance. \n",
    "\n",
    "Once you are happy with the performance you can move on and have a look once again at our forecast from 2022 to see if it improved.\n",
    "\n",
    "It is important to mention, though, that all these steps can always be repeated which will always change the results. So usually, we need to do hyperparameter tuning for all the models that we are comparing and for each set of optimal hyperparameters we need to do feature selection. And if we then continue with further optimisation steps (like adding predictors, data cleaning...) it gets even more complex to find the best model. Another key point regarding model optimisation is that it is always just done for a subset of the data (i.e. the validation set). A model optimised for this validation set, is not necessarily the best model in general. All this points together make it impossible to find the optimal model, so there will always need to be compromises, especially if you do not have much data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d529f-24e2-4435-8ef2-0328e7a08fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictors for current lead time\n",
    "predictors = [col for col in used_file.columns if col[-3:-1]==\"LT\"]\n",
    "used_predictors = [a for a in predictors if int(a[-1]) >= lead_time]\n",
    "\n",
    "# Lets make a forecast for the latest year in the dataset 2022\n",
    "# Thus, we split the data into training (years before 2022) and testing (year 2022)\n",
    "test_ind = np.where(used_file.loc[:, 'YEAR']==2022)[0]\n",
    "train_ind = np.where(used_file.loc[:, 'YEAR']!=2022)[0]\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test = used_file.loc[train_ind, used_predictors], used_file.loc[test_ind, used_predictors]\n",
    "y_train, y_test = used_file.loc[train_ind, 'VALUE'], used_file.loc[test_ind, 'VALUE']\n",
    "regs = used_file.loc[test_ind, 'IDREGION']\n",
    "\n",
    "# Define model and pipeline\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "data_df = pd.DataFrame({\n",
    "    'region_name': regs,\n",
    "    'y_test': y_test,\n",
    "    'y_pred': y_pred\n",
    "})\n",
    "\n",
    "# Merge the shapefile with your data\n",
    "# Replace 'REGION_NAME_COLUMN' with the actual column name in your shapefile that contains region names\n",
    "gdf_merged = nuts_areas.merge(data_df, left_on='NUTS_ID', right_on='region_name', how='left')\n",
    "\n",
    "# Calculate shared colorbar range\n",
    "vmin = min(min(y_test), min(y_pred))\n",
    "vmax = max(max(y_test), max(y_pred))\n",
    "norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Create the three plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: Spatial plot colored by y_test\n",
    "gdf_merged.plot(column='y_test',\n",
    "                ax=axes[0],\n",
    "                cmap='viridis',\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                edgecolor='black',\n",
    "                linewidth=0.5)\n",
    "axes[0].set_title('Actual Values (y_test)', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Plot 2: Spatial plot colored by y_pred\n",
    "gdf_merged.plot(column='y_pred',\n",
    "                ax=axes[1],\n",
    "                cmap='viridis',\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                edgecolor='black',\n",
    "                linewidth=0.5)\n",
    "axes[1].set_title('Predicted Values (y_pred)', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Add colorbar between first two plots\n",
    "sm = cm.ScalarMappable(norm=norm, cmap='viridis')\n",
    "sm.set_array([])\n",
    "# Position the colorbar between axes[0] and axes[1]\n",
    "cbar_ax = fig.add_axes([0.31, 0.15, 0.01, 0.7])  # [left, bottom, width, height]\n",
    "cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "cbar.set_label('Yield [t/ha]', fontsize=14)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "# Plot 3: Scatterplot with x=y line\n",
    "axes[2].scatter(y_test, y_pred, alpha=0.7)\n",
    "axes[2].set_xlabel('y_test (Actual)', fontsize=14)\n",
    "axes[2].set_ylabel('y_pred (Predicted)', fontsize=14)\n",
    "axes[2].set_title('Predicted vs Actual', fontsize=16)\n",
    "axes[2].tick_params(labelsize=12)\n",
    "\n",
    "# Add x=y line\n",
    "min_val = min(min(y_test), min(y_pred))\n",
    "max_val = max(max(y_test), max(y_pred))\n",
    "perf = np.round(r2_score(y_test, y_pred),2)\n",
    "axes[2].plot([min_val, max_val], [min_val, max_val], 'r--', label=f'x=y\\nR¬≤={perf}')\n",
    "axes[2].set_xlim(min_val, max_val)\n",
    "axes[2].set_ylim(min_val, max_val)\n",
    "axes[2].legend(fontsize=14)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if initial_perf<perf:\n",
    "    print(f'Well done! You have improved your model performance by an R¬≤ of {perf-initial_perf:.2f}')\n",
    "else:\n",
    "    print('Unfortunately, you have not improved the model performance. Keep trying.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf71ff9-7fe4-4872-bb89-af1cba3c9a41",
   "metadata": {},
   "source": [
    "Finally, we can also look at the feature importance to get some information about how much the predictors impact the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e6ee30-be96-4e26-96e3-f80ac64c8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time = 0\n",
    "X_train, X_test, y_train, y_test, years_train, years_test = train_test_split(used_file, lead_time)\n",
    "\n",
    "estimator = xgb.XGBRegressor(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42  # Added for reproducibility\n",
    ")\n",
    "pipeline = Pipeline([('scalar', StandardScaler()), ('xgb', estimator)])\n",
    "\n",
    "# Train pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Extract the trained model from pipeline\n",
    "model = pipeline.named_steps['xgb']\n",
    "\n",
    "# Use pipeline transform on X_test before passing to explainer if needed\n",
    "X_test_transformed = pipeline[:-1].transform(X_test)  # apply all steps except the final estimator\n",
    "\n",
    "# Create SHAP explainer using transformed train input\n",
    "X_train_transformed = pipeline[:-1].transform(X_train)\n",
    "explainer = shap.Explainer(model, X_train_transformed)\n",
    "\n",
    "# Calculate SHAP values on transformed test input\n",
    "shap_values = explainer(X_test_transformed)\n",
    "\n",
    "# Plot SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_test_transformed, feature_names=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953dc55f-ad39-4d75-9704-c1b473ea7646",
   "metadata": {},
   "source": [
    "üéâüéâWell done! You have successfully learned how to do crop yield forecasting ü•≥ü•≥\n",
    "\n",
    "You are very welcome to play around with the code and try to further improve the model. Especially adding other predictors like latitude/longitude or year or using different models may help to do so. Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410490e6-635f-4b1d-8dd7-7566010b671e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
